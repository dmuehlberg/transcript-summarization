Bitte erweitere den bestehenden FastAPI-Service processing-service im Projekt transcript_summarization um folgende Funktionalit√§t:

‚∏ª

üß© Neuer Endpoint: /update_transcript_data

Implementiere einen neuen POST-Endpoint /update_transcript_data, der das Verzeichnis
/shared/transcription_finished durchsucht und dort alle .json- und .txt-Paare verarbeitet.

Dateibenennung:
Die Dateien folgen dem Muster YYYY-MM-DD HH-MM-SS.txt bzw. .json. Aus dem Dateinamen soll ein Zeitstempel (recording_date) extrahiert werden. Falls dieser nicht extrahiert werden kann, verwende datetime.now().

‚∏ª

üìÇ Was soll eingelesen werden?

F√ºr jede Transkription existieren:
	‚Ä¢	eine .txt-Datei mit dem Transkriptions-Text
	‚Ä¢	eine .json-Datei mit dem gleichen Basisnamen, die folgendes enth√§lt:
	‚Ä¢	metadata.language ‚Üí detected_language
	‚Ä¢	metadata.duration ‚Üí transcription_duration
	‚Ä¢	metadata.audio_duration ‚Üí audio_duration

Verwende die JSON-Struktur aus folgendem Beispiel als Referenz:
Die JSON-Datei enth√§lt ein Array mit einem Objekt (also Zugriff auf [0]).

‚∏ª

üóÑÔ∏è PostgreSQL-Tabelle: transcriptions

Beim Start des processing-service soll gepr√ºft werden, ob die Tabelle transcriptions existiert. Falls nicht, erstelle sie mit folgendem Schema:

Spalte	Typ	Beschreibung
id	SERIAL PRIMARY KEY	Eindeutiger Identifier
filepath	TEXT	Pfad zur .txt-Datei
recording_date	TIMESTAMP	Extrahierter oder aktueller Zeitstempel
detected_language	TEXT	Aus JSON (metadata.language)
set_language	TEXT	Manuell ausw√§hlbare Sprache (initial NULL)
transcript_text	TEXT	Inhalt der .txt-Datei
corrected_text	TEXT	Text nach phonetischer Korrektur (initial leer)
participants_firstname	TEXT	Vornamen, kommasepariert (initial leer)
participants_lastname	TEXT	Nachnamen, kommasepariert (initial leer)
transcription_duration	FLOAT	Aus JSON (metadata.duration)
audio_duration	FLOAT	Aus JSON (metadata.audio_duration)
created_at	TIMESTAMP	Zeitstempel des DB-Eintrags (jetzt)

Wenn ein Datensatz mit identischem filepath bereits existiert, √ºberschreibe ihn.

‚∏ª

üßæ Verarbeitungsschritte
	1.	Liste alle .json-Dateien in /shared/transcription_finished auf.
	2.	F√ºr jede .json-Datei:
	‚Ä¢	Extrahiere den Basenamen (ohne Endung)
	‚Ä¢	Lade zugeh√∂rige .txt-Datei
	‚Ä¢	Lade die JSON-Datei (Array-Zugriff: [0])
	‚Ä¢	Extrahiere:
	‚Ä¢	metadata.language
	‚Ä¢	metadata.duration
	‚Ä¢	metadata.audio_duration
	‚Ä¢	Analysiere Dateinamen zur Bestimmung von recording_date
	‚Ä¢	Schreibe oder √ºberschreibe den Datensatz in der Tabelle transcriptions

‚∏ª

üåê Budibase-Integration

Erg√§nze die docker-compose.yml im Projekt-Root um folgenden Budibase-Container:

  budibase:
    image: budibase/budibase:latest
    ports:
      - "8400:80"
    environment:
      - INTERNAL_POSTGRES_ENABLED=false
    depends_on:
      - postgres

Budibase soll Zugriff auf dieselbe PostgreSQL-Datenbank wie n8n haben.
Das Feld set_language in der Tabelle transcriptions soll in Budibase als Dropdown-Feld mit den Werten de und en editierbar sein.

‚∏ª

üõ† Technische Hinweise
	‚Ä¢	Verwende SQLAlchemy oder psycopg2 f√ºr den Datenbankzugriff
	‚Ä¢	Dateinamen-Parsing z.‚ÄØB. mit Regex: (\d{4}-\d{2}-\d{2}) (\d{2}-\d{2}-\d{2})
	‚Ä¢	F√ºge bei jedem Eintrag ein created_at = datetime.utcnow() hinzu
	‚Ä¢	Nutze UTF-8 beim Einlesen der .txt-Dateien

‚∏ª

Setze die komplette Funktionalit√§t in processing-service um. Integriere den neuen Endpoint in die vorhandene main.py oder router.py. Erg√§nze ggf. eine neue Datei db.py oder schema.py f√ºr das Tabellenmodell.