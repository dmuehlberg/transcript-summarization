# Verwenden Sie ein stabileres CUDA-Runtime-Image mit integriertem cuDNN
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

ENV PYTHON_VERSION=3.11
# Stellen Sie sicher, dass sowohl die CUDA- als auch die cuDNN-Bibliotheken im Pfad sind
ENV LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/include:/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH

# Install dependencies and clean up in the same layer
RUN export DEBIAN_FRONTEND=noninteractive \
    && apt-get -y update \
    && apt-get -y install --no-install-recommends \
    software-properties-common \
    && add-apt-repository ppa:deadsnakes/ppa \
    && apt-get -y update \
    && apt-get -y install --no-install-recommends \
    python3.11 \
    python3-pip \
    git \
    ffmpeg \
    # Wir brauchen kein zusätzliches cuDNN-Paket, da es im Base-Image enthalten ist
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/* \
    && ln -s -f /usr/bin/python${PYTHON_VERSION} /usr/bin/python3 \
    && ln -s -f /usr/bin/python${PYTHON_VERSION} /usr/bin/python

# Install UV for package management
COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /bin/

WORKDIR /app

# Copy application code
COPY app app/
COPY tests tests/
COPY app/gunicorn_logging.conf .
COPY requirements requirements/

# Überprüfen und anzeigen der CUDA-Bibliotheken und ihrer Pfade für Diagnosezwecke
RUN find /usr -name "libcudnn*.so*" | sort

# Ändern Sie die PyTorch-Installation zu einer Version, die mit CUDA 11.8 und cuDNN 8 kompatibel ist
RUN uv pip install --system --no-cache-dir torch==2.0.1+cu118 -i https://download.pytorch.org/whl/cu118 \
    && uv pip install --system --no-cache-dir -r requirements/prod.txt \
    # Clean pip cache and temporary files
    && rm -rf /root/.cache /tmp/*

# Explizite Tests auf CUDA-Verfügbarkeit
RUN python -c "import torch; print('CUDA available:', torch.cuda.is_available()); print('PyTorch version:', torch.__version__); print('CUDA version:', torch.version.cuda if torch.cuda.is_available() else 'NA')"

EXPOSE 8000

# Erhöhen Sie die Anzahl der Worker, wenn Sie genug GPUs und Speicher haben
ENTRYPOINT ["gunicorn", "--bind", "0.0.0.0:8000", "--workers", "1", "--timeout", "0", "--log-config", "gunicorn_logging.conf", "app.main:app", "-k", "uvicorn.workers.UvicornWorker"]