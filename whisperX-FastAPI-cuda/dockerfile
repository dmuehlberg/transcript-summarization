# Verwenden eines stabileren CUDA-Images mit cuDNN
FROM nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04

ENV PYTHON_VERSION=3.11
ENV LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/include:/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH

# Kopiere ein Skript zum Container-Setup
COPY setup_container.sh /tmp/setup_container.sh
RUN chmod +x /tmp/setup_container.sh && /tmp/setup_container.sh

WORKDIR /app

# Copy application code
COPY app app/
COPY tests tests/
COPY app/gunicorn_logging.conf .
COPY requirements requirements/

# Zeige die verfügbaren cuDNN-Bibliotheken für Diagnose 
RUN find /usr -name "libcudnn*.so*" 2>/dev/null | sort

# Verifiziere die PyTorch-Installation
RUN python -c "import torch; print('CUDA available:', torch.cuda.is_available()); print('PyTorch version:', torch.__version__); print('CUDA version:', torch.version.cuda if torch.cuda.is_available() else 'N/A')"

EXPOSE 8000

ENTRYPOINT ["gunicorn", "--bind", "0.0.0.0:8000", "--workers", "1", "--timeout", "0", "--log-config", "gunicorn_logging.conf", "app.main:app", "-k", "uvicorn.workers.UvicornWorker"]